{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Automatic colour correction: adjusting the brightness, contrast, and colour balance of an image to make it more visually pleasing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "h2ZuZlMzqeF0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "hsv[:,:,2] = hsv[:,:,2]*1.2 \n",
    "img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "cv2.imwrite(\"output.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Downloading Pillow-9.4.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 149.7 kB/s eta 0:00:00\n",
      "Installing collected packages: pillow\n",
      "Successfully installed pillow-9.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"image.jpg\")\n",
    "img = img.convert(\"RGB\")\n",
    "img = ImageEnhance.Color(img).enhance(1.2) # increase color by 20%\n",
    "img.save(\"output.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Image restoration: removing noise, blur, or other distortions from an image to improve its quality. \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "dst = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "cv2.imshow(\"Denoised Image\", dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Object removal: removing unwanted objects from an image, such as a person or a piece of trash. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\t\n",
    "\n",
    "# Opening the image and converting\n",
    "# it to RGB color mode\n",
    "# IMAGE_PATH => Path to the image\n",
    "img = Image.open(r\"C:\\Users\\abhij\\OneDrive\\Desktop\\New folder\\image.jpg\").convert('RGB')\n",
    "\n",
    "# Extracting the image data &\n",
    "# creating an numpy array out of it\n",
    "img_arr = np.array(img)\n",
    "\n",
    "# Turning the pixel values of the 400x400 pixels to black\n",
    "img_arr[0 : 400, 0 : 400] = (0, 0, 0)\n",
    "\n",
    "# Creating an image out of the previously modified array\n",
    "img = Image.fromarray(img_arr)\n",
    "\n",
    "# Displaying the image\n",
    "img.show()\n",
    "img.save(\"output3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ImageDraw for\n",
    "# using floodfill function\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "img = Image.open(r\"C:\\Users\\abhij\\OneDrive\\Desktop\\New folder\\mask.jpeg\").convert('RGBA')\n",
    "\n",
    "# Location of seed\n",
    "seed = (0, 8)\n",
    "\n",
    "# Pixel Value which would\n",
    "# be used for replacement.\n",
    "rep_value = (0, 0, 9, 0)\n",
    "\n",
    "# Calling the floodfill() function and\n",
    "# passing it image, seed, value and\n",
    "# thresh as arguments\n",
    "ImageDraw.floodfill(img, seed, rep_value, thresh = 100)\n",
    "\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Image style transfer: applying the artistic style of one image to another image, such as making a photo look like a painting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\python311\\lib\\site-packages (22.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import cv2\n",
    "\n",
    "# Read the input image\n",
    "image = cv2.imread('man3.jpg')\n",
    "\n",
    "# define haar cascade for face detection\n",
    "face_cascade =\n",
    "cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "faces = face_cascade.detectMultiScale(image, 1.3, 5)\n",
    "print(\"Face detected in the image:\", len(faces))\n",
    "\n",
    "# Loop over all the detected faces in the image\n",
    "for (x, y, w, h) in faces:\n",
    "   roi = image[y:y+h, x:x+w]\n",
    " \n",
    "   # apply gaussian blur to face rectangle\n",
    "   roi = cv2.GaussianBlur(roi, (17, 17), 30)\n",
    " \n",
    "   # add blurred face on original image to get final image\n",
    "   image[y:y+roi.shape[0], x:x+roi.shape[1]] = roi\n",
    "\n",
    "# Display the output\n",
    "cv2.imshow('Blur Face', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m label_map_util\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m visualization_utils \u001b[39mas\u001b[39;00m vis_util\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# Load a pre-trained model for object detection\n",
    "model = tf.saved_model.load(\"path/to/model\")\n",
    "\n",
    "# Load the label map for the model, which maps class IDs to class names\n",
    "label_map = label_map_util.load_labelmap(\"path/to/label_map.pbtxt\")\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# Read in the image file\n",
    "image = tf.io.read_file(\"path/to/image.jpg\")\n",
    "image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "# Run the model on the image to get predictions\n",
    "predictions = model(image)\n",
    "\n",
    "# Extract the bounding boxes and class IDs for the dog breeds\n",
    "boxes = predictions[\"detection_boxes\"]\n",
    "classes = predictions[\"detection_classes\"]\n",
    "scores = predictions[\"detection_scores\"]\n",
    "\n",
    "# Filter the predictions to only include those with a high enough confidence score\n",
    "min_score_thresh = 0.5\n",
    "indices = tf.where(scores > min_score_thresh)\n",
    "boxes = tf.gather(boxes, indices)\n",
    "classes = tf.gather(classes, indices)\n",
    "scores = tf.gather(scores, indices)\n",
    "\n",
    "# Draw the bounding boxes and class names on the image\n",
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "    image,\n",
    "    boxes.numpy(),\n",
    "    classes.numpy(),\n",
    "    scores.numpy(),\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    min_score_thresh=min_score_thresh,\n",
    "    agnostic_mode=False)\n",
    "\n",
    "# Save the image with the bounding boxes and class names\n",
    "tf.io.write_file(\"path/to/output_image.jpg\", tf.image.encode_jpeg(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
